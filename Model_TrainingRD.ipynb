{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to directories for datasets\n",
    "train_combined_dir = r\"C:\\Users\\grand\\Downloads\\Dataset\\Train\\Combined\"\n",
    "validation_combined_dir = r\"C:\\Users\\grand\\Downloads\\Dataset\\Validation\\Combined\"\n",
    "test_combined_dir = r\"C:\\Users\\grand\\Downloads\\Dataset\\Test\\Combined\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Data Generators (Rescale pixel values and augment)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load Pre-trained VGG16 Model (used for feature extraction)\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "model = Model(inputs=base_model.input, outputs=base_model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Create Image Generators\n",
    "def create_train_generator():\n",
    "    \"\"\"Create image generator for training.\"\"\"\n",
    "    return train_datagen.flow_from_directory(\n",
    "        train_combined_dir,  \n",
    "        target_size=(224, 224),  \n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True,\n",
    "        seed=42  # Set seed for reproducibility\n",
    "    )\n",
    "\n",
    "def create_validation_generator():\n",
    "    \"\"\"Create image generator for validation.\"\"\"\n",
    "    return valid_datagen.flow_from_directory(\n",
    "        validation_combined_dir,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "def create_test_generator():\n",
    "    \"\"\"Create image generator for testing.\"\"\"\n",
    "    return test_datagen.flow_from_directory(\n",
    "        test_combined_dir,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Extract Features from Images\n",
    "def extract_features(generator, sample_count):\n",
    "    \"\"\"Extract features using the VGG16 model.\"\"\"\n",
    "    features = np.zeros(shape=(sample_count, 7, 7, 512))  \n",
    "    labels = np.zeros(shape=(sample_count, generator.num_classes))\n",
    "    \n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = model.predict(inputs_batch)\n",
    "        features[i * generator.batch_size : (i + 1) * generator.batch_size] = features_batch\n",
    "        labels[i * generator.batch_size : (i + 1) * generator.batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * generator.batch_size >= sample_count:\n",
    "            break\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1322 images belonging to 3 classes.\n",
      "Found 60 images belonging to 3 classes.\n",
      "Found 150 images belonging to 3 classes.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n"
     ]
    }
   ],
   "source": [
    "# Create Generators\n",
    "train_generator = create_train_generator()\n",
    "validation_generator = create_validation_generator()\n",
    "test_generator = create_test_generator()\n",
    "\n",
    "# Extract Features for Training, Validation, and Testing Sets\n",
    "train_features, train_labels = extract_features(train_generator, train_generator.samples)\n",
    "valid_features, valid_labels = extract_features(validation_generator, validation_generator.samples)\n",
    "test_features, test_labels = extract_features(test_generator, test_generator.samples)\n",
    "\n",
    "# Reshape the features for Random Forest\n",
    "train_features = np.reshape(train_features, (train_features.shape[0], 7 * 7 * 512))\n",
    "valid_features = np.reshape(valid_features, (valid_features.shape[0], 7 * 7 * 512))\n",
    "test_features = np.reshape(test_features, (test_features.shape[0], 7 * 7 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model saved as 'random_forest_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Convert labels from categorical to numerical\n",
    "train_labels_numeric = np.argmax(train_labels, axis=1)\n",
    "valid_labels_numeric = np.argmax(valid_labels, axis=1)\n",
    "test_labels_numeric = np.argmax(test_labels, axis=1)\n",
    "\n",
    "# Initialize and Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(train_features, train_labels_numeric)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(rf_model, 'random_forest_model.pkl')\n",
    "\n",
    "print(\"Random Forest model saved as 'random_forest_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 88.33%\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.95      0.86        20\n",
      "           1       0.90      0.95      0.93        20\n",
      "           2       1.00      0.75      0.86        20\n",
      "\n",
      "    accuracy                           0.88        60\n",
      "   macro avg       0.90      0.88      0.88        60\n",
      "weighted avg       0.90      0.88      0.88        60\n",
      "\n",
      "Validation Confusion Matrix:\n",
      " [[19  1  0]\n",
      " [ 1 19  0]\n",
      " [ 4  1 15]]\n",
      "Test Accuracy: 84.00%\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84        50\n",
      "           1       0.91      0.84      0.88        50\n",
      "           2       0.83      0.78      0.80        50\n",
      "\n",
      "    accuracy                           0.84       150\n",
      "   macro avg       0.84      0.84      0.84       150\n",
      "weighted avg       0.84      0.84      0.84       150\n",
      "\n",
      "Test Confusion Matrix:\n",
      " [[45  1  4]\n",
      " [ 4 42  4]\n",
      " [ 8  3 39]]\n"
     ]
    }
   ],
   "source": [
    "# Predict on the validation set\n",
    "y_pred_val = rf_model.predict(valid_features)\n",
    "\n",
    "# Evaluate the Model on Validation Set\n",
    "print(f'Validation Accuracy: {accuracy_score(valid_labels_numeric, y_pred_val) * 100:.2f}%')\n",
    "print(\"Validation Classification Report:\\n\", classification_report(valid_labels_numeric, y_pred_val))\n",
    "print(\"Validation Confusion Matrix:\\n\", confusion_matrix(valid_labels_numeric, y_pred_val))\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_test = rf_model.predict(test_features)\n",
    "\n",
    "# Evaluate the Model on Test Set\n",
    "print(f'Test Accuracy: {accuracy_score(test_labels_numeric, y_pred_test) * 100:.2f}%')\n",
    "print(\"Test Classification Report:\\n\", classification_report(test_labels_numeric, y_pred_test))\n",
    "print(\"Test Confusion Matrix:\\n\", confusion_matrix(test_labels_numeric, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Predict New Input\n",
    "def predict_new_image(image_path):\n",
    "    \"\"\"Predict the class of a new image using the Random Forest model.\"\"\"\n",
    "    img = load_img(image_path, target_size=(224, 224))  # Load and resize the image\n",
    "    x = img_to_array(img)  # Convert image to array\n",
    "    x = x.astype('float32') / 255.  # Normalize\n",
    "    x = np.expand_dims(x, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Extract features using VGG16 model\n",
    "    features = model.predict(x)\n",
    "    features = np.reshape(features, (1, 7 * 7 * 512))  # Reshape for Random Forest input\n",
    "\n",
    "    # Predict using Random Forest\n",
    "    prediction = rf_model.predict(features)\n",
    "    \n",
    "    return prediction[0]  # Return the predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 769ms/step\n",
      "The predicted class for the image is: 1\n",
      "The predicted label for the image is: Powdery\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "new_image_path = r\"C:\\Users\\grand\\Downloads\\Dataset\\Test\\Test\\Powdery\\9ec7295cb1d44c2d.jpg\"  # Update this with the path to the image\n",
    "predicted_class = predict_new_image(new_image_path)\n",
    "print(f'The predicted class for the image is: {predicted_class}')\n",
    "\n",
    "# Optional: Mapping numerical predictions to class labels\n",
    "class_labels = {0: 'Healthy', 1: 'Powdery', 2: 'Rust'}  # Replace with your actual labels\n",
    "predicted_label = class_labels.get(predicted_class, 'Unknown')  # Use get to handle potential missing keys\n",
    "print(f'The predicted label for the image is: {predicted_label}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
